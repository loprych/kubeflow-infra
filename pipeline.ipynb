{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830a6047-e57d-4fd2-a68a-3cb1941dbc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: kubernetes in /opt/conda/lib/python3.11/site-packages (30.1.0)\n",
      "Requirement already satisfied: minio in /opt/conda/lib/python3.11/site-packages (7.2.15)\n",
      "Requirement already satisfied: click<9,>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (8.1.7)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.16)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.20.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.35.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.18.2)\n",
      "Requirement already satisfied: kfp-pipeline-spec==0.4.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: kfp-server-api<2.4.0,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=4.21.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (4.25.5)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.11/site-packages (from kfp) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (1.26.20)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.9.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (3.2.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from minio) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.11/site-packages (from minio) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from minio) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (1.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->kubernetes) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->kubernetes) (3.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp) (0.6.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp kubernetes minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddbcec4-d349-4293-9a60-547b04c4ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import requests\n",
    "import os\n",
    "from minio import Minio\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Input, Output, Artifact, Model, component\n",
    "from kfp.dsl import InputPath, OutputPath, pipeline\n",
    "from kubernetes.client.models import V1EnvVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dca57cc-95aa-4e7f-b060-a1c1ce020a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime',\n",
    "    packages_to_install=['ultralytics','minio','opencv-python-headless','pyyaml']\n",
    ")\n",
    "def train(\n",
    "    trained_model_output: Output[Artifact],\n",
    "    training_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    dataset_path: str = \"dataset\",\n",
    "    base_model: str = \"yolov8n.pt\"\n",
    "):\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import yaml\n",
    "\n",
    "    subprocess.run(['apt-get', 'update'], check=True)\n",
    "    subprocess.run(['apt-get', 'install', '-y', 'libgl1-mesa-glx', 'libglib2.0-0'], check=True)\n",
    "    subprocess.run(['rm', '-rf', '/var/lib/apt/lists/*'], check=True)\n",
    "\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        dataset_dir = temp_dir / \"dataset\"\n",
    "        model_dir = temp_dir / \"model\"\n",
    "        log_path   = temp_dir / \"training_logs.txt\"\n",
    "\n",
    "        for subdir in ['images/train','images/val','labels/train','labels/val']:\n",
    "            (dataset_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        objects = client.list_objects(minio_bucket, prefix=dataset_path, recursive=True)\n",
    "        for obj in objects:\n",
    "            if obj.object_name.endswith('/'):\n",
    "                continue\n",
    "            rel_path = obj.object_name[len(dataset_path):].lstrip('/')\n",
    "            if not rel_path:\n",
    "                continue\n",
    "            local_path = dataset_dir / rel_path\n",
    "            local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            client.fget_object(minio_bucket, obj.object_name, str(local_path))\n",
    "\n",
    "        yaml_path = dataset_dir / \"data.yaml\"\n",
    "        if yaml_path.exists():\n",
    "            import yaml\n",
    "            with open(yaml_path, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            data_config['train'] = str(dataset_dir/'images/train')\n",
    "            data_config['val']   = str(dataset_dir/'images/val')\n",
    "            with open(yaml_path,'w') as f:\n",
    "                yaml.dump(data_config,f)\n",
    "\n",
    "        base_model_local = model_dir / base_model\n",
    "        client.fget_object(minio_bucket, f\"model/{base_model}\", str(base_model_local))\n",
    "\n",
    "        model = YOLO(str(base_model_local))\n",
    "        results = model.train(\n",
    "            data=str(yaml_path),\n",
    "            epochs=5,\n",
    "            imgsz=640,\n",
    "            batch=4,\n",
    "            patience=3,\n",
    "            device='cpu',\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        trained_model_local = model_dir / \"trained_model.pt\"\n",
    "        model.save(str(trained_model_local))\n",
    "\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"model/trained_yolo_model.pt\",\n",
    "            str(trained_model_local)\n",
    "        )\n",
    "\n",
    "        with open(log_path, 'w') as f:\n",
    "            f.write(\"=== TRAINING COMPLETE ===\\n\")\n",
    "            f.write(str(results) + \"\\n\")\n",
    "\n",
    "        with open(trained_model_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(trained_model_local, 'rb').read())\n",
    "\n",
    "        with open(training_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(log_path, 'r').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5d9b5a-cae0-48fa-a09d-a3aa5c740ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime',\n",
    "    packages_to_install=['torch-model-archiver', 'minio', 'torchserve', 'ultralytics']\n",
    ")\n",
    "def package_to_mar(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    trained_mar_output: Output[Artifact],\n",
    "    base_mar_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    base_model_path: str = \"model/yolov8n.pt\"\n",
    "):\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    from minio import Minio\n",
    "    import subprocess\n",
    "    import os\n",
    "\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        trained_model_path = temp_dir / \"trained_yolo_model.pt\"\n",
    "        base_model_path_local = temp_dir / \"yolov8n.pt\"\n",
    "        model_store = temp_dir / \"model-store\"\n",
    "        model_store.mkdir(exist_ok=True)\n",
    "        handler_path = temp_dir / \"yolo_handler.py\"\n",
    "        \n",
    "        # Write handler\n",
    "        with open(handler_path, \"w\") as f:\n",
    "            f.write(\"\"\"import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from ts.torch_handler.object_detector import ObjectDetector\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    XLA_AVAILABLE = True\n",
    "except ImportError as error:\n",
    "    XLA_AVAILABLE = False\n",
    "\n",
    "class Yolov8Handler(ObjectDetector):\n",
    "    image_processing = transforms.Compose([\n",
    "        transforms.Resize(640),\n",
    "        transforms.CenterCrop(640),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Yolov8Handler, self).__init__()\n",
    "\n",
    "    def initialize(self, context):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        elif XLA_AVAILABLE:\n",
    "            self.device = xm.xla_device()\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        properties = context.system_properties\n",
    "        self.manifest = context.manifest\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.model_pt_path = None\n",
    "        if \"serializedFile\" in self.manifest[\"model\"]:\n",
    "            serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "            self.model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        self.model = self._load_torchscript_model(self.model_pt_path)\n",
    "        logger.debug(\"Model file %s loaded successfully\", self.model_pt_path)\n",
    "        self.initialized = True\n",
    "\n",
    "    def _load_torchscript_model(self, model_pt_path):\n",
    "        model = YOLO(model_pt_path)\n",
    "        model.to(self.device)\n",
    "        return model\n",
    "\n",
    "    def preprocess(self, requests):\n",
    "        images = []\n",
    "        for data in requests:\n",
    "            image = data.get(\"data\") or data.get(\"body\")\n",
    "            if isinstance(image, str):\n",
    "                image = base64.b64decode(image)\n",
    "            image = Image.open(io.BytesIO(image)).convert('RGB')\n",
    "            image = self.image_processing(image)\n",
    "            images.append(image)\n",
    "        return torch.stack(images).to(self.device)\n",
    "\n",
    "    def inference(self, data):\n",
    "        results = self.model(data)\n",
    "        return results\n",
    "\n",
    "    def postprocess(self, res):\n",
    "        output = []\n",
    "        for data in res:\n",
    "            classes = data.boxes.cls.tolist()\n",
    "            names = data.names\n",
    "            classes = map(lambda cls: names[int(cls)], classes)\n",
    "            result = Counter(classes)\n",
    "            output.append(dict(result))\n",
    "        return output\"\"\")\n",
    "\n",
    "        # Create requirements file\n",
    "        requirements_path = temp_dir / \"requirements.txt\"\n",
    "        with open(requirements_path, \"w\") as f:\n",
    "            f.write(\"torch\\nPillow\\nultralytics\\ntorchvision\\n\")\n",
    "\n",
    "        # Copy trained model\n",
    "        print(f\"Copying trained model to {trained_model_path}\")\n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(trained_model_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        if not trained_model_path.exists():\n",
    "            raise FileNotFoundError(f\"Trained model was not copied to {trained_model_path}\")\n",
    "        \n",
    "        # Get base model\n",
    "        print(f\"Getting base model from MinIO\")\n",
    "        client.fget_object(\n",
    "            minio_bucket,\n",
    "            base_model_path,\n",
    "            str(base_model_path_local)\n",
    "        )\n",
    "        \n",
    "        if not base_model_path_local.exists():\n",
    "            raise FileNotFoundError(f\"Base model was not downloaded to {base_model_path_local}\")\n",
    "        \n",
    "        # Package trained model\n",
    "        print(\"Creating trained model MAR file...\")\n",
    "        result = subprocess.run([\n",
    "            'torch-model-archiver',\n",
    "            '--model-name', 'trained_yolo_model', \n",
    "            '--version', '1.0',\n",
    "            '--serialized-file', str(trained_model_path),\n",
    "            '--handler', str(handler_path),\n",
    "            '--requirements-file', str(requirements_path),\n",
    "            '--export-path', str(model_store),\n",
    "            '--force'\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"Error creating trained MAR file: {result.stderr}\")\n",
    "        \n",
    "        # Package base model\n",
    "        print(\"Creating base model MAR file...\")\n",
    "        result = subprocess.run([\n",
    "            'torch-model-archiver',\n",
    "            '--model-name', 'base_yolo_model', \n",
    "            '--version', '1.0',\n",
    "            '--serialized-file', str(base_model_path_local),\n",
    "            '--handler', str(handler_path),\n",
    "            '--requirements-file', str(requirements_path),\n",
    "            '--export-path', str(model_store),\n",
    "            '--force'\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"Error creating base MAR file: {result.stderr}\")\n",
    "            \n",
    "        trained_mar_path = model_store / \"trained_yolo_model.mar\"\n",
    "        base_mar_path = model_store / \"base_yolo_model.mar\"\n",
    "        \n",
    "        if not trained_mar_path.exists() or not base_mar_path.exists():\n",
    "            raise FileNotFoundError(f\"MAR files were not created: {trained_mar_path}, {base_mar_path}\")\n",
    "            \n",
    "        print(f\"MAR files created at: {trained_mar_path} and {base_mar_path}\")\n",
    "        \n",
    "        # Save to MinIO\n",
    "        print(\"Saving to MinIO...\")\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"kserve/model-store/trained_yolo_model.mar\",\n",
    "            str(trained_mar_path)\n",
    "        )\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"kserve/model-store/base_yolo_model.mar\",\n",
    "            str(base_mar_path)\n",
    "        )\n",
    "        \n",
    "        # Save outputs\n",
    "        print(\"Saving outputs...\")\n",
    "        with open(trained_mar_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(trained_mar_path, 'rb').read())\n",
    "        with open(base_mar_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(base_mar_path, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e6cb1b-5e41-452b-b571-19f4b38bbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime',\n",
    "    packages_to_install=['ultralytics','minio','opencv-python-headless','pyyaml']\n",
    ")\n",
    "def evaluate_model(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    evaluation_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str\n",
    "):\n",
    "    import subprocess\n",
    "    subprocess.run(['apt-get','update'],check=True)\n",
    "    subprocess.run(['apt-get','install','-y','libgl1-mesa-glx','libglib2.0-0'],check=True)\n",
    "    subprocess.run(['rm','-rf','/var/lib/apt/lists/*'],check=True)\n",
    "    import os\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        model_local_path = temp_dir / \"trained_model.pt\"\n",
    "        eval_log_path = temp_dir / \"eval_logs.txt\"\n",
    "        \n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(model_local_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        image_paths = []\n",
    "        for img_name in [\"zidane.jpg\", \"bus.jpg\"]:\n",
    "            image_local = temp_dir / img_name\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img_name}\",\n",
    "                    str(image_local)\n",
    "                )\n",
    "                image_paths.append(image_local)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not download {img_name}: {e}\")\n",
    "                # Try to download from ultralytics\n",
    "                try:\n",
    "                    from ultralytics.utils.downloads import download\n",
    "                    download(f\"https://ultralytics.com/images/{img_name}\", str(image_local))\n",
    "                    image_paths.append(image_local)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Could not download image from backup source: {e2}\")\n",
    "        \n",
    "        model = YOLO(str(model_local_path))\n",
    "        \n",
    "        with open(eval_log_path, 'w') as f:\n",
    "            f.write(\"=== EVALUATION RESULTS ===\\n\")\n",
    "            for img_path in image_paths:\n",
    "                f.write(f\"\\nEvaluating image: {img_path.name}\\n\")\n",
    "                results = model(str(img_path))\n",
    "                f.write(f\"Detection results: {results[0].boxes.shape[0]} objects found\\n\")\n",
    "                \n",
    "                # Detailed metrics\n",
    "                boxes = results[0].boxes\n",
    "                if len(boxes) > 0:\n",
    "                    f.write(f\"Average confidence: {boxes.conf.mean().item():.4f}\\n\")\n",
    "                    f.write(f\"Maximum confidence: {boxes.conf.max().item():.4f}\\n\")\n",
    "                    \n",
    "                    # Class distribution\n",
    "                    classes = boxes.cls.tolist()\n",
    "                    names = results[0].names\n",
    "                    class_counts = {}\n",
    "                    for cls in classes:\n",
    "                        cls_name = names[int(cls)]\n",
    "                        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
    "                    \n",
    "                    f.write(\"Class distribution:\\n\")\n",
    "                    for cls_name, count in class_counts.items():\n",
    "                        f.write(f\"  - {cls_name}: {count}\\n\")\n",
    "                        \n",
    "                f.write(f\"Results: {results}\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        # Save logs to output artifact\n",
    "        with open(evaluation_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(eval_log_path, 'r').read())\n",
    "            \n",
    "        # Also save to MinIO with specific name\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            \"evaluation/eval_logs.txt\",\n",
    "            open(eval_log_path, 'rb'),\n",
    "            length=os.path.getsize(str(eval_log_path))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849ca085-b254-4575-a651-ecc5f260dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime',\n",
    "    packages_to_install=['ultralytics','minio','opencv-python-headless','pyyaml']\n",
    ")\n",
    "def inference_model(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    inference_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str\n",
    "):\n",
    "    import subprocess\n",
    "    subprocess.run(['apt-get','update'],check=True)\n",
    "    subprocess.run(['apt-get','install','-y','libgl1-mesa-glx','libglib2.0-0'],check=True)\n",
    "    subprocess.run(['rm','-rf','/var/lib/apt/lists/*'],check=True)\n",
    "    import os\n",
    "    import tempfile\n",
    "    import time\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        model_local_path = temp_dir / \"trained_model.pt\"\n",
    "        inference_log_path = temp_dir / \"inference_logs.txt\"\n",
    "        result_images_dir = temp_dir / \"results\"\n",
    "        result_images_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(model_local_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        # Get test images\n",
    "        images = [\"zidane.jpg\", \"bus.jpg\"]\n",
    "        local_img_paths = []\n",
    "        \n",
    "        for img in images:\n",
    "            local_img = temp_dir / img\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img}\",\n",
    "                    str(local_img)\n",
    "                )\n",
    "                local_img_paths.append(local_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not download {img}: {e}\")\n",
    "                # Try to download from ultralytics\n",
    "                try:\n",
    "                    from ultralytics.utils.downloads import download\n",
    "                    download(f\"https://ultralytics.com/images/{img}\", str(local_img))\n",
    "                    local_img_paths.append(local_img)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Could not download image from backup source: {e2}\")\n",
    "        \n",
    "        model = YOLO(str(model_local_path))\n",
    "        timestamp = int(time.time())\n",
    "        \n",
    "        with open(inference_log_path, 'w') as f:\n",
    "            f.write(\"=== INFERENCE RESULTS ===\\n\")\n",
    "            f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "            f.write(f\"Model: {model_local_path}\\n\\n\")\n",
    "            \n",
    "            for img_path in local_img_paths:\n",
    "                f.write(f\"Image: {img_path.name}\\n\")\n",
    "                # Run inference with visualization\n",
    "                results = model(str(img_path), save=True, save_dir=str(result_images_dir))\n",
    "                \n",
    "                # Save detailed results\n",
    "                boxes = results[0].boxes\n",
    "                f.write(f\"Detection count: {len(boxes)}\\n\")\n",
    "                \n",
    "                if len(boxes) > 0:\n",
    "                    f.write(f\"Average confidence: {boxes.conf.mean().item():.4f}\\n\")\n",
    "                    f.write(f\"Classes detected: {len(set(boxes.cls.tolist()))}\\n\")\n",
    "                    \n",
    "                    # Class distribution with confidence\n",
    "                    classes = boxes.cls.tolist()\n",
    "                    confs = boxes.conf.tolist()\n",
    "                    names = results[0].names\n",
    "                    \n",
    "                    f.write(\"Detections:\\n\")\n",
    "                    for i, (cls, conf) in enumerate(zip(classes, confs)):\n",
    "                        cls_name = names[int(cls)]\n",
    "                        f.write(f\"  {i+1}. {cls_name} (confidence: {conf:.4f})\\n\")\n",
    "                \n",
    "                f.write(f\"Raw results: {results}\\n\")\n",
    "                f.write(\"-\" * 60 + \"\\n\\n\")\n",
    "                \n",
    "                # Upload result images to MinIO if they exist\n",
    "                result_img = result_images_dir / img_path.name\n",
    "                if result_img.exists():\n",
    "                    try:\n",
    "                        client.fput_object(\n",
    "                            minio_bucket,\n",
    "                            f\"inference/results/{timestamp}_{img_path.name}\",\n",
    "                            str(result_img)\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        f.write(f\"Failed to upload result image: {e}\\n\")\n",
    "        \n",
    "        # Save to artifact output\n",
    "        with open(inference_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(inference_log_path, 'r').read())\n",
    "            \n",
    "        # Also save to MinIO with specific name\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            \"inference/inference_logs.txt\",\n",
    "            open(inference_log_path, 'rb'),\n",
    "            length=os.path.getsize(str(inference_log_path))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0156ce51-ceaf-4e70-91ad-a2c398ea84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime',\n",
    "    packages_to_install=['ultralytics', 'minio', 'opencv-python-headless', 'pyyaml']\n",
    ")\n",
    "def compare_models(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    model_comparison_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    base_model_path: str = \"model/yolov8n.pt\",\n",
    "    previous_trained_model_path: str = \"model/trained_yolo_model.pt\",\n",
    "    accuracy_threshold: float = 0.03  # 3% improvement required\n",
    "):\n",
    "    import subprocess\n",
    "    subprocess.run(['apt-get', 'update'], check=True)\n",
    "    subprocess.run(['apt-get', 'install', '-y', 'libgl1-mesa-glx', 'libglib2.0-0'], check=True)\n",
    "    subprocess.run(['rm', '-rf', '/var/lib/apt/lists/*'], check=True)\n",
    "    \n",
    "    import os\n",
    "    import tempfile\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    import time\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        new_model_path = temp_dir / \"new_model.pt\"\n",
    "        prev_model_path = temp_dir / \"previous_model.pt\"\n",
    "        base_model_local_path = temp_dir / \"base_model.pt\"\n",
    "        validation_images_dir = temp_dir / \"validation_images\"\n",
    "        validation_images_dir.mkdir(exist_ok=True)\n",
    "        comparison_results_path = temp_dir / \"comparison_results.json\"\n",
    "        \n",
    "        # Copy the new model from input\n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(new_model_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        # Check if this is the first training run or if previous trained model exists\n",
    "        previous_model_exists = True\n",
    "        try:\n",
    "            # Use timestamp to check if the previous trained model is not the same as current one\n",
    "            prev_stats = client.stat_object(minio_bucket, previous_trained_model_path)\n",
    "            curr_time = time.time()\n",
    "            # If the model was created in the last hour, it's likely from the current run\n",
    "            # In that case, compare against the base model\n",
    "            if (curr_time - prev_stats.last_modified.timestamp()) < 3600:\n",
    "                print(\"Previous trained model is likely from current run, comparing against base model\")\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    base_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "            else:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    previous_trained_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Previous trained model not found: {e}\")\n",
    "            print(\"Will compare against base model instead\")\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    base_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "            except Exception as e2:\n",
    "                print(f\"Base model not found either: {e2}\")\n",
    "                previous_model_exists = False\n",
    "        \n",
    "        # Get validation images\n",
    "        val_images = [\"zidane.jpg\", \"bus.jpg\"]\n",
    "        for img in val_images:\n",
    "            local_img = validation_images_dir / img\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img}\",\n",
    "                    str(local_img)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not fetch validation image {img}: {e}\")\n",
    "                # Try to use demo images from ultralytics\n",
    "                import shutil\n",
    "                from ultralytics.utils.downloads import download\n",
    "                download(f\"https://ultralytics.com/images/{img}\", str(local_img))\n",
    "        \n",
    "        # Load new model\n",
    "        new_model = YOLO(str(new_model_path))\n",
    "        \n",
    "        # Evaluate new model\n",
    "        new_model_metrics = {}\n",
    "        for img_name in val_images:\n",
    "            img_path = validation_images_dir / img_name\n",
    "            if not img_path.exists():\n",
    "                print(f\"Skipping missing image: {img_name}\")\n",
    "                continue\n",
    "                \n",
    "            results = new_model(str(img_path))\n",
    "            # Extract confidence scores and metrics\n",
    "            boxes = results[0].boxes\n",
    "            new_model_metrics[img_name] = {\n",
    "                'num_detections': len(boxes),\n",
    "                'avg_confidence': float(boxes.conf.mean()) if len(boxes) > 0 else 0,\n",
    "                'max_confidence': float(boxes.conf.max()) if len(boxes) > 0 else 0\n",
    "            }\n",
    "        \n",
    "        comparison_result = {\n",
    "            'new_model_metrics': new_model_metrics,\n",
    "            'previous_model_metrics': {},\n",
    "            'is_better': True,  # Default to True if no previous model exists\n",
    "            'improvement': 0,\n",
    "            'message': 'First model, no comparison available'\n",
    "        }\n",
    "        \n",
    "        if previous_model_exists:\n",
    "            # Load previous model\n",
    "            prev_model = YOLO(str(prev_model_path))\n",
    "            \n",
    "            # Evaluate previous model\n",
    "            prev_model_metrics = {}\n",
    "            for img_name in val_images:\n",
    "                img_path = validation_images_dir / img_name\n",
    "                if not img_path.exists():\n",
    "                    continue\n",
    "                    \n",
    "                results = prev_model(str(img_path))\n",
    "                boxes = results[0].boxes\n",
    "                prev_model_metrics[img_name] = {\n",
    "                    'num_detections': len(boxes),\n",
    "                    'avg_confidence': float(boxes.conf.mean()) if len(boxes) > 0 else 0,\n",
    "                    'max_confidence': float(boxes.conf.max()) if len(boxes) > 0 else 0\n",
    "                }\n",
    "            \n",
    "            comparison_result['previous_model_metrics'] = prev_model_metrics\n",
    "            \n",
    "            # Calculate metrics:\n",
    "            # 1. Average confidence across all images\n",
    "            # 2. Total detections (weighted by confidence)\n",
    "            \n",
    "            # Get valid images that both models processed\n",
    "            valid_images = set(new_model_metrics.keys()) & set(prev_model_metrics.keys())\n",
    "            if not valid_images:\n",
    "                comparison_result['message'] = \"No common images to compare models\"\n",
    "                comparison_result['is_better'] = True\n",
    "            else:\n",
    "                # Calculate weighted detection score (num_detections * avg_confidence)\n",
    "                new_score = sum(\n",
    "                    new_model_metrics[img]['num_detections'] * new_model_metrics[img]['avg_confidence']\n",
    "                    for img in valid_images\n",
    "                ) / len(valid_images)\n",
    "                \n",
    "                prev_score = sum(\n",
    "                    prev_model_metrics[img]['num_detections'] * prev_model_metrics[img]['avg_confidence']\n",
    "                    for img in valid_images\n",
    "                ) / len(valid_images)\n",
    "                \n",
    "                improvement = (new_score - prev_score) / max(prev_score, 0.001)\n",
    "                \n",
    "                comparison_result['improvement'] = float(improvement)\n",
    "                comparison_result['is_better'] = improvement >= accuracy_threshold\n",
    "                \n",
    "                if comparison_result['is_better']:\n",
    "                    comparison_result['message'] = f\"New model is better by {improvement:.2%}\"\n",
    "                else:\n",
    "                    comparison_result['message'] = (\n",
    "                        f\"New model does not meet improvement threshold. \"\n",
    "                        f\"Improvement: {improvement:.2%}, Required: {accuracy_threshold:.2%}\"\n",
    "                    )\n",
    "        \n",
    "        # Save comparison results\n",
    "        with open(comparison_results_path, 'w') as f:\n",
    "            json.dump(comparison_result, f, indent=2)\n",
    "        \n",
    "        # Save to MinIO as well\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            \"comparison/model_comparison.json\",\n",
    "            open(comparison_results_path, 'rb'),\n",
    "            length=os.path.getsize(str(comparison_results_path))\n",
    "        )\n",
    "        \n",
    "        with open(model_comparison_output.path, 'w') as out_f:\n",
    "            out_f.write(open(comparison_results_path, 'r').read())\n",
    "        \n",
    "        # Important: We no longer raise an exception here!\n",
    "        # Instead, we just report the results and let the serve component decide\n",
    "        print(f\"Comparison complete: {comparison_result['message']}\")\n",
    "        print(f\"Model is better: {comparison_result['is_better']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8efdfe2-86f4-48a9-8829-9d5a8a775d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['kubernetes', 'PyYAML', 'minio']\n",
    ")\n",
    "def serve(\n",
    "    trained_mar_input: Input[Artifact],\n",
    "    base_mar_input: Input[Artifact],\n",
    "    model_comparison_input: Input[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    service_namespace: str = \"kubeflow-user-example-com\"\n",
    "):\n",
    "    import kubernetes\n",
    "    import yaml\n",
    "    import os\n",
    "    import json\n",
    "    from minio import Minio\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import io\n",
    "    \n",
    "    # Connect to MinIO\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Read comparison results to determine which model to serve\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        comparison_path = temp_dir / \"comparison_results.json\"\n",
    "        deploy_log_path = temp_dir / \"deployment_logs.txt\"\n",
    "        model_path = temp_dir / \"model.mar\"\n",
    "        \n",
    "        with open(model_comparison_input.path, 'r') as in_f:\n",
    "            with open(comparison_path, 'w') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "                \n",
    "        with open(comparison_path, 'r') as f:\n",
    "            comparison_results = json.load(f)\n",
    "        \n",
    "        # Determine which model to copy as the active model\n",
    "        with open(deploy_log_path, 'w') as log_f:\n",
    "            log_f.write(\"=== DEPLOYMENT LOGS ===\\n\")\n",
    "            \n",
    "            if comparison_results.get('is_better', True):\n",
    "                log_f.write(\"Selecting trained model - it performs better\\n\")\n",
    "                log_f.write(f\"Improvement: {comparison_results.get('improvement', 0):.2%}\\n\")\n",
    "                # Copy trained model to local path\n",
    "                with open(trained_mar_input.path, 'rb') as src, open(model_path, 'wb') as dst:\n",
    "                    dst.write(src.read())\n",
    "            else:\n",
    "                log_f.write(\"Selecting base model - trained model did not show sufficient improvement\\n\")\n",
    "                # Copy base model to local path\n",
    "                with open(base_mar_input.path, 'rb') as src, open(model_path, 'wb') as dst:\n",
    "                    dst.write(src.read())\n",
    "            \n",
    "            log_f.write(f\"Reason: {comparison_results.get('message', 'No comparison data available')}\\n\")\n",
    "            \n",
    "            # Upload selected model to MinIO using the file path\n",
    "            try:\n",
    "                client.fput_object(\n",
    "                    minio_bucket,\n",
    "                    \"kserve/model-store/yolo_model.mar\",\n",
    "                    str(model_path)\n",
    "                )\n",
    "                log_f.write(\"Successfully uploaded model to MinIO\\n\")\n",
    "            except Exception as e:\n",
    "                log_f.write(f\"Error uploading model to MinIO: {str(e)}\\n\")\n",
    "                raise\n",
    "        \n",
    "        # Upload deployment logs to MinIO\n",
    "        try:\n",
    "            client.fput_object(\n",
    "                minio_bucket,\n",
    "                \"deployment/deployment_logs.txt\",\n",
    "                str(deploy_log_path)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading deployment logs: {str(e)}\")\n",
    "    \n",
    "    # Configure Kubernetes\n",
    "    kubernetes.config.load_incluster_config()\n",
    "    api_instance = kubernetes.client.CustomObjectsApi()\n",
    "    \n",
    "    # Use fixed service definition with correct storageUri path\n",
    "    inference_service = {\n",
    "        \"apiVersion\": \"serving.kserve.io/v1beta1\",\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\n",
    "            \"name\": \"yolov8\",\n",
    "            \"namespace\": service_namespace\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"predictor\": {\n",
    "                \"serviceAccountName\": \"sa-minio-kserve\",\n",
    "                \"model\": {\n",
    "                    \"modelFormat\": {\n",
    "                        \"name\": \"pytorch\"\n",
    "                    },\n",
    "                    \"storageUri\": \"s3://mlpipeline/kserve\",\n",
    "                    \"protocolVersion\": \"v2\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Deploying InferenceService 'yolov8' in namespace {service_namespace}\")\n",
    "    print(f\"Using storageUri: s3://mlpipeline/kserve\")\n",
    "    \n",
    "    try:\n",
    "        response = api_instance.create_namespaced_custom_object(\n",
    "            group=\"serving.kserve.io\",\n",
    "            version=\"v1beta1\",\n",
    "            namespace=service_namespace,\n",
    "            plural=\"inferenceservices\",\n",
    "            body=inference_service\n",
    "        )\n",
    "        print(f\"InferenceService created: {response['metadata']['name']}\")\n",
    "    except kubernetes.client.rest.ApiException as e:\n",
    "        if e.status == 409:\n",
    "            print(\"InferenceService already exists, updating\")\n",
    "            response = api_instance.replace_namespaced_custom_object(\n",
    "                group=\"serving.kserve.io\",\n",
    "                version=\"v1beta1\",\n",
    "                namespace=service_namespace,\n",
    "                plural=\"inferenceservices\",\n",
    "                name=\"yolov8\",\n",
    "                body=inference_service\n",
    "            )\n",
    "            print(f\"InferenceService updated: {response['metadata']['name']}\")\n",
    "        else:\n",
    "            print(f\"Error creating/updating InferenceService: {e}\")\n",
    "            raise\n",
    "    \n",
    "    print(\"InferenceService has been deployed. Check its status manually.\")\n",
    "    print(f\"Service will be available at: yolov8.{service_namespace}.example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c26ba1c-0d20-44c8-b207-9ba1fd8a4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation successful -> yolo_pipeline.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/kfp/client/client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/82c9adaf-2906-4b14-a81d-027d0bab9688\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/7aace7c0-a52d-4373-969e-ab9e14c4bdbe\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline run submitted: 7aace7c0-a52d-4373-969e-ab9e14c4bdbe\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    name='YOLOv8 Pipeline with Quality Gate',\n",
    "    description='YOLOv8 pipeline with model quality validation before serving'\n",
    ")\n",
    "def yolo_pipeline():\n",
    "    config = {\n",
    "        'minio_endpoint': 'minio-service.kubeflow:9000',\n",
    "        'minio_access_key': 'minio',\n",
    "        'minio_secret_key': 'minio123',\n",
    "        'minio_bucket': 'mlpipeline'\n",
    "    }\n",
    "    \n",
    "    # Training step\n",
    "    train_task = train(\n",
    "        **config,\n",
    "        base_model=\"yolov8n.pt\",\n",
    "        dataset_path=\"dataset\"\n",
    "    )\n",
    "    train_task.set_cpu_request('2')\n",
    "    train_task.set_memory_request('4G')\n",
    "    \n",
    "    # Package both models to MAR\n",
    "    package_task = package_to_mar(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        base_model_path=\"model/yolov8n.pt\",\n",
    "        **config\n",
    "    )\n",
    "    package_task.after(train_task)\n",
    "    \n",
    "    # Evaluation step\n",
    "    eval_task = evaluate_model(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config\n",
    "    )\n",
    "    eval_task.after(package_task)\n",
    "    \n",
    "    # Inference step\n",
    "    inference_task = inference_model(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config\n",
    "    )\n",
    "    inference_task.after(eval_task)\n",
    "    \n",
    "    # Model comparison quality gate\n",
    "    compare_task = compare_models(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config,\n",
    "        base_model_path=\"model/yolov8n.pt\",\n",
    "        previous_trained_model_path=\"model/trained_yolo_model.pt\",\n",
    "        accuracy_threshold=0.03  # Require 3% improvement\n",
    "    )\n",
    "    compare_task.after(inference_task)\n",
    "    \n",
    "    # Conditionally serve the better model\n",
    "    serve_task = serve(\n",
    "        trained_mar_input=package_task.outputs[\"trained_mar_output\"],\n",
    "        base_mar_input=package_task.outputs[\"base_mar_output\"],\n",
    "        model_comparison_input=compare_task.outputs[\"model_comparison_output\"],\n",
    "        **config,\n",
    "        service_namespace=\"kubeflow-user-example-com\"\n",
    "    )\n",
    "    serve_task.after(compare_task)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    from kfp import compiler\n",
    "    pipeline_package_path = \"yolo_pipeline.yaml\"\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=yolo_pipeline,\n",
    "        package_path=pipeline_package_path\n",
    "    )\n",
    "    print(f\"Compilation successful -> {pipeline_package_path}\")\n",
    "    \n",
    "    from kfp import Client\n",
    "    client = Client()  \n",
    "    run = client.create_run_from_pipeline_package(\n",
    "        pipeline_file=pipeline_package_path,\n",
    "        arguments={}\n",
    "    )\n",
    "    print(\"Pipeline run submitted:\", run.run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
